{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d34d68cc894025",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/bmalcover/cursSocib/blob/main/2_AA/2_5_Unet_practice.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "## Unet in practice\n",
    "\n",
    "In this exercise, we will implement an image segmentation pipeline to identify the boundary between land and sea in coastal images using a U-Net architecture.\n",
    "\n",
    "We will train a deep learning model based on U-Net to perform binary segmentation on aerial images of coastal regions. The goal is to produce a mask that highlights the coastline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59624aa86e851faf",
   "metadata": {},
   "source": [
    "### Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9bd71bbefec9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T08:30:38.486745Z",
     "start_time": "2025-06-25T08:30:36.207631Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNetMini(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super(UNetMini, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(in_channels, 32)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = self.conv_block(32, 64)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.conv_block(64, 128)\n",
    "\n",
    "        # Decoder\n",
    "\n",
    "        # TODO\n",
    "\n",
    "        # Output\n",
    "        self.out_conv = nn.Conv2d(32, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(self.pool2(e2))\n",
    "\n",
    "        # Decoder\n",
    "        \n",
    "        # TODO\n",
    "\n",
    "        # Output\n",
    "        return F.sigmoid(self.out_conv(d1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abcd345df4e5671",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5453981dc6cd69a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T08:31:30.502432Z",
     "start_time": "2025-06-25T08:31:29.084443Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, target_transform=None):\n",
    "        self.img_dir = os.path.join(root_dir, 'images')\n",
    "        self.mask_dir = os.path.join(root_dir, 'masks')\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        self.img_filenames = sorted(os.listdir(self.img_dir))\n",
    "        self.mask_filenames = sorted(os.listdir(self.mask_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_filenames[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_filenames[idx])\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            mask = self.target_transform(mask)\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137b7a70887a039a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T20:31:28.485881Z",
     "start_time": "2025-06-23T20:31:28.458882Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transforms for the image (normalization and augmentation, if desired)\n",
    "img_transforms = T.Compose([\n",
    "    T.Resize((128, 128)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Transforms for the mask (only resizing and conversion to tensor)\n",
    "mask_transforms = T.Compose([\n",
    "    T.Resize((128, 128), interpolation=Image.NEAREST),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# Dataset & DataLoader creation\n",
    "dataset = SegmentationDataset(root_dir='../data/coastline',\n",
    "                               transform=img_transforms,\n",
    "                               target_transform=mask_transforms)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Split\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoaders for each dataset split\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc3f3b73566c10",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ddc2f90d09c009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T20:31:31.170091Z",
     "start_time": "2025-06-23T20:31:30.894862Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "model = UNetMini()\n",
    "\n",
    "# Hiperparameters\n",
    "epochs = 15\n",
    "learning_rate = 1e-3  \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b63987678c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import pylab as pl\n",
    "\n",
    "\n",
    "running_loss = []\n",
    "running_val_loss = []\n",
    "\n",
    "pbar = tqdm(range(1, epochs + 1))  # tdqm permet tenir text dinàmic\n",
    "\n",
    "for epoch in pbar:\n",
    "\n",
    "    model.train()  # Posam el model a mode entrenament.\n",
    "    batch_loss = 0\n",
    "    for i_batch, (x, y) in enumerate(train_loader):\n",
    "\n",
    "        # 1. PREDICCIÓ\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # 2. CALCUL DE LA PÈRDUA\n",
    "        # Computa la pèrdua: l'error de predicció vs el valor correcte\n",
    "        # Es guarda la pèrdua en un array per futures visualitzacions\n",
    "\n",
    "        loss = F.binary_cross_entropy(y_pred, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Actualitza els pesos utilitzant l'algorisme d'actualització\n",
    "        #4. OPTIMITZACIO\n",
    "        with torch.no_grad():\n",
    "            optimizer.step()\n",
    "        #3. GRADIENT\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_loss += loss.detach().numpy()\n",
    "    running_loss.append(batch_loss / len(train_loader))\n",
    "\n",
    "    batch_test_loss = 0\n",
    "    batch_test_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    for i_batch, (x, y) in enumerate(val_loader):\n",
    "        \n",
    "        y_pred = model(x)        \n",
    "        batch_test_loss +=  F.binary_cross_entropy(y_pred, y).detach().numpy()\n",
    "\n",
    "    running_val_loss.append(batch_test_loss / (len(val_loader)))\n",
    "    \n",
    "    # VISUALITZACIO DINAMICA\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    pl.plot(running_loss[:epoch], label=\"train\")\n",
    "    pl.plot(running_val_loss[:epoch], label=\"validation\")\n",
    "    pl.legend()\n",
    "    pl.xlim(0, epochs)\n",
    "    pl.xticks(range(0, epochs, 1), range(1, epochs + 1, 1))\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(pl.gcf())\n",
    "    plt.close()\n",
    "\n",
    "    pbar.set_description(f\"Epoch:{epoch} Training Loss:{running_loss[epoch-1]} Validation Loss:{running_val_loss[epoch-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392610d1-40c1-408a-b64e-0c27a22514fd",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Your task is to run inference process with the U-Net model. That means using the model on the test set to get the segmentation  masks that highlight the areas of interest. Run the model, and look at the output masks to see what the model has detected.\n",
    "\n",
    "**Extra**\n",
    "\n",
    "Load an image from internet and observe the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a977608d-9eaa-4836-8f5c-20ed86e81f67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T18:59:13.508530Z",
     "start_time": "2025-07-01T18:59:13.502531Z"
    }
   },
   "outputs": [],
   "source": [
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31dd51a-12ab-4375-9191-efdd0d252ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b432ce57d7f51c22",
   "metadata": {},
   "source": [
    "In this second stage we will compute the IOU on the train set and we will compare it with the results from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552a6e57-2682-4de6-9acb-ff6ac37e2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def binary_iou(mask_pred, mask_true):\n",
    "    \"\"\"\n",
    "    Compute IoU for binary masks.\n",
    "\n",
    "    Args:\n",
    "        mask_pred (np.ndarray): Predicted mask (0 or 1), shape (H, W) or (N, H, W)\n",
    "        mask_true (np.ndarray): Ground truth mask (0 or 1), same shape as mask_pred\n",
    "\n",
    "    Returns:\n",
    "        float: IoU score\n",
    "    \"\"\"\n",
    "    intersection = np.logical_and(mask_pred, mask_true).sum()\n",
    "    union = np.logical_or(mask_pred, mask_true).sum()\n",
    "    if union == 0:\n",
    "        return 1.0 if intersection == 0 else 0.0  # Perfect match or meaningless\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b78614ba2cc8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
