{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "670dbe7bb8bdee1d",
   "metadata": {},
   "source": [
    "## YOLO Practice\n",
    "\n",
    "In this section we will make some simple exercises to understand the YOLO-Ultralytics ecosystem.\n",
    "\n",
    "As we explained before YOLO is a powerful object detection model, but it is not typically used on its own; instead, it requires an environment that handles preprocessing, inference, and postprocessing. The most common and user-friendly implementation today is the Ultralytics ecosystem, which wraps YOLO in a complete framework with tools for training, validation, prediction, and export. This environment includes pre-trained models, utilities for dataset handling, making it practical and accessible. Without such a framework, using YOLO directly would involve complex low-level coding and management of its architecture and weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7624a505-b421-4e7f-8aec-800e40dab7e9",
   "metadata": {},
   "source": [
    "### Exercise 1: First Detection with YOLOv8\n",
    "\n",
    "In this exercise,we will perform object detection on an image using a pretrained YOLOv8 model within the Ultralytics framework.\n",
    "\n",
    "**Instructions**:\n",
    "- Load the `yolov8n.pt` model from the `ultralytics` package.\n",
    "- Use a local image or an image URL as input.\n",
    "- Display the image with bounding boxes and class labels for each detection.\n",
    "\n",
    "**Results**\n",
    "- Visualize detections over the image\n",
    "- Print the number of objects detected per class.\n",
    "\n",
    "\n",
    "You can use next image for testing: [image](https://static.dw.com/image/18585189_1004.webp)\n",
    "\n",
    "**Extra**\n",
    "- Try to load an image from your computer using `cv2.imread` [example](https://www.geeksforgeeks.org/python/python-opencv-cv2-imread-method/) or PIL `open` [example](https://www.geeksforgeeks.org/python/python-pil-image-open-method/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5956fa5c-03ee-4847-914b-2fd62ff237a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a40d48-43dc-4a03-a907-368c3c68c990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T06:30:11.500069Z",
     "start_time": "2025-07-01T06:30:11.494002Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cdc32d8-8ff2-427a-a0c5-8ea7ea4b1648",
   "metadata": {},
   "source": [
    "It's very interesting (necessary) to deep in the results type: [Documentation](https://docs.ultralytics.com/reference/engine/results/#ultralytics.engine.results.Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd2407c-21c9-4b9e-8183-aab86762b110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6e11b7b-1799-40a9-8593-7892a46db2b2",
   "metadata": {},
   "source": [
    "### Exercise 2: Filter Detections by Class\n",
    "\n",
    "Show only the detections of a specific class (e.g., people or bicycles) in an image.\n",
    "\n",
    "**Instructions**:\n",
    "- Reuse the code from Exercise 1 (as much as you can).\n",
    "- Filter the detection results to only include objects of class `\"person\"`.\n",
    "- Display the filtered results over the original image.\n",
    "\n",
    "**Extra**\n",
    "- Try to filter detections with confidence greater than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0063e30c-af81-4e15-ae54-16552e10601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results[0].names;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1cc1b9-b294-4a42-8ecf-20fe2e7baccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ba2455b-4b27-4663-80d0-4a7ba0129abf",
   "metadata": {},
   "source": [
    "### Exercise 3: Export Detections to CSV\n",
    "\n",
    "In this exercise we will save object detection results to a `.csv` file.\n",
    "\n",
    "**Instructions**:\n",
    "- Use the `yolov8n.pt` model to detect objects in an image.\n",
    "- For each detection, store: class name, confidence score, and bounding box coordinates (`x1, y1, x2, y2`).\n",
    "- Write the results to a CSV file using `pandas` or `csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7abde8b4-a216-4294-a983-02248a69fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b86c11b-3370-4439-91ba-615bdde33355",
   "metadata": {},
   "source": [
    "### Exercise 4: Image Segmentation\n",
    "\n",
    "In this exercises we will apply object segmentation on an image using a pretrained segmentation model.\n",
    "\n",
    "**Instructions**:\n",
    "- Use the `yolov8n-seg.pt` model.\n",
    "- Predict segmentations for an input image.\n",
    "- Display the image with both bounding boxes and segmentation masks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f6967f-01be-4139-9a50-5cd305863ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f577f6a1-f937-4d4f-92b3-07b823b0c0e4",
   "metadata": {},
   "source": [
    "#### 4.1 Mask inspection\n",
    "Let's gain a deeper understanding of the mask format. In this (sub)exercises we will try to draw the mask with the highest confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c876b65b-c6b3-4dc5-99bf-65bf2c1c8f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e26c1e0-8619-44ca-8ef1-70b2b545dfca",
   "metadata": {},
   "source": [
    "### Exercise 5: Detection vs. Segmentation Comparison\n",
    "\n",
    "This exercise pretends to visually compare object detection and segmentation results on the same image.\n",
    "\n",
    "**Instructions**:\n",
    "- Use both `yolov8n.pt` (detection) and `yolov8n-seg.pt` (segmentation).\n",
    "- Run both predictions on the same image.\n",
    "- Show the two outputs side by side.\n",
    "\n",
    "**Final Questions**:\n",
    "- How does segmentation improve or worsen the results compared to detection?\n",
    "- In what scenarios would segmentation be more useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a1d88-c829-4dc8-9922-289c964759ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
