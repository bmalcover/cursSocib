{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Unet Practice\n",
    "\n",
    "In this exercise, we will implement an image segmentation pipeline to identify the boundary between land and sea in coastal images using a U-Net architecture.\n",
    "\n",
    "We will train a deep learning model based on U-Net to perform binary segmentation on aerial images of coastal regions. The goal is to produce a mask that highlights the coastline.\n"
   ],
   "id": "55d34d68cc894025"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Network definition",
   "id": "59624aa86e851faf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T20:31:17.439144Z",
     "start_time": "2025-06-23T20:31:14.116592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNetMini(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super(UNetMini, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(in_channels, 32)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = self.conv_block(32, 64)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.conv_block(64, 128)\n",
    "\n",
    "        # Decoder\n",
    "        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(128, 64)\n",
    "        self.up1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(64, 32)\n",
    "\n",
    "        # Output\n",
    "        self.out_conv = nn.Conv2d(32, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(self.pool2(e2))\n",
    "\n",
    "        # Decoder\n",
    "        d2 = self.up2(b)\n",
    "        d2 = self.dec2(torch.cat([d2, e2], dim=1))\n",
    "        d1 = self.up1(d2)\n",
    "        d1 = self.dec1(torch.cat([d1, e1], dim=1))\n",
    "\n",
    "        # Output\n",
    "        return F.sigmoid(self.out_conv(d1))\n"
   ],
   "id": "b9bd71bbefec9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data preparation",
   "id": "8abcd345df4e5671"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T20:31:23.146515Z",
     "start_time": "2025-06-23T20:31:20.980082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, target_transform=None):\n",
    "        self.img_dir = os.path.join(root_dir, 'images')\n",
    "        self.mask_dir = os.path.join(root_dir, 'masks')\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        self.img_filenames = sorted(os.listdir(self.img_dir))\n",
    "        self.mask_filenames = sorted(os.listdir(self.mask_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_filenames[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_filenames[idx])\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            mask = self.target_transform(mask)\n",
    "\n",
    "        return image, mask\n"
   ],
   "id": "5453981dc6cd69a5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T20:31:28.485881Z",
     "start_time": "2025-06-23T20:31:28.458882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transforms per a la imatge (normalització i augmentació si vols)\n",
    "img_transforms = T.Compose([\n",
    "    T.Resize((128, 128)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Transforms per a la màscara (només resize i conversió a tensor)\n",
    "mask_transforms = T.Compose([\n",
    "    T.Resize((128, 128), interpolation=Image.NEAREST),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# Crear dataset i DataLoader\n",
    "dataset = SegmentationDataset(root_dir='data/coastline',\n",
    "                               transform=img_transforms,\n",
    "                               target_transform=mask_transforms)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divisió\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoaders per a cada conjunt\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n"
   ],
   "id": "137b7a70887a039a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train",
   "id": "70fc3f3b73566c10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T20:31:31.170091Z",
     "start_time": "2025-06-23T20:31:30.894862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "epochs = 40\n",
    "model = UNetMini()\n",
    "learning_rate = 1e-3  # Hiperparàmetre\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "id": "40ddc2f90d09c009",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import pylab as pl\n",
    "\n",
    "\n",
    "running_loss = []\n",
    "running_val_loss = []\n",
    "\n",
    "pbar = tqdm(range(1, epochs + 1))  # tdqm permet tenir text dinàmic\n",
    "\n",
    "for epoch in pbar:\n",
    "\n",
    "    model.train()  # Posam el model a mode entranament.\n",
    "    batch_loss = 0\n",
    "    for i_batch, (x, y) in enumerate(train_loader):\n",
    "\n",
    "        # 1. PREDICCIÓ\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # 2. CALCUL DE LA PÈRDUA\n",
    "        # Computa la pèrdua: l'error de predicció vs el valor correcte\n",
    "        # Es guarda la pèrdua en un array per futures visualitzacions\n",
    "\n",
    "        loss = F.binary_cross_entropy(y_pred, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Actualitza els pesos utilitzant l'algorisme d'actualització\n",
    "        #4. OPTIMITZACIO\n",
    "        with torch.no_grad():\n",
    "            optimizer.step()\n",
    "        #3. GRADIENT\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_loss += loss.detach().numpy()\n",
    "    running_loss.append(batch_loss / len(train_loader))\n",
    "\n",
    "    batch_test_loss = 0\n",
    "    batch_test_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    for i_batch, (x, y) in enumerate(val_loader):\n",
    "        \n",
    "        y_pred = model(x)        \n",
    "        batch_test_loss +=  F.binary_cross_entropy(y_pred, y).detach().numpy()\n",
    "\n",
    "    running_val_loss.append(batch_test_loss / (len(val_loader)))\n",
    "    \n",
    "    # VISUALITZACIO DINAMICA\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    pl.plot(running_loss[:epoch], label=\"train\")\n",
    "    pl.plot(running_val_loss[:epoch], label=\"validation\")\n",
    "    pl.legend()\n",
    "    pl.xlim(0, epochs)\n",
    "    pl.xticks(range(0, epochs, 1), range(1, epochs + 1, 1))\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(pl.gcf())\n",
    "    plt.close()\n",
    "\n",
    "    pbar.set_description(f\"Epoch:{epoch} Training Loss:{running_loss[epoch-1]} Validation Loss:{running_val_loss[epoch-1]}\")"
   ],
   "id": "cd4b63987678c54e",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 25\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# 2. CALCUL DE LA PÈRDUA\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# Computa la pèrdua: l'error de predicció vs el valor correcte\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# Es guarda la pèrdua en un array per futures visualitzacions\u001B[39;00m\n\u001B[0;32m     24\u001B[0m loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mbinary_cross_entropy(y_pred, y)\n\u001B[1;32m---> 25\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# Actualitza els pesos utilitzant l'algorisme d'actualització\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m#4. OPTIMITZACIO\u001B[39;00m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\torch\\_tensor.py:521\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    512\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    513\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    514\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    519\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    520\u001B[0m     )\n\u001B[1;32m--> 521\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    284\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    286\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 289\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    290\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    291\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    292\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    293\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    294\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    295\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    296\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    297\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\torch\\autograd\\graph.py:769\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    767\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    768\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 769\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    770\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    771\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    772\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    773\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
